{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization is the process of tokenizing or splitting a string, text into a list of tokens. One can think of token as parts like a word is a token in a sentence, and a sentence is a token in a paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shivan\\Anaconda3\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\shivan\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 2117, in run\n",
      "    for msg in self.data_server.incr_download(self.items):\n",
      "  File \"C:\\Users\\shivan\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 630, in incr_download\n",
      "    for msg in self._download_list(info_or_id, download_dir, force):\n",
      "  File \"C:\\Users\\shivan\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 676, in _download_list\n",
      "    for msg in self.incr_download(item, download_dir, force):\n",
      "  File \"C:\\Users\\shivan\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 644, in incr_download\n",
      "    for msg in self.incr_download(info.children, download_dir, force):\n",
      "  File \"C:\\Users\\shivan\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 630, in incr_download\n",
      "    for msg in self._download_list(info_or_id, download_dir, force):\n",
      "  File \"C:\\Users\\shivan\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 676, in _download_list\n",
      "    for msg in self.incr_download(item, download_dir, force):\n",
      "  File \"C:\\Users\\shivan\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 650, in incr_download\n",
      "    for msg in self._download_package(info, download_dir, force):\n",
      "  File \"C:\\Users\\shivan\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 704, in _download_package\n",
      "    os.remove(filepath)\n",
      "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\shivan\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\abc.zip'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = \"\"\"Well that’s just disappointing: it takes 5 minutes to just tokenize 100000 notes. This is kind of annoying if you are playing with hyperparameters of a Vectorizer for your NLP Bag-of-words model. Note that the cleaning function plays a minimal role with this tokenizer (12 seconds out of 291 seconds). Let’s see if we can do better.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Well that’s just disappointing: it takes 5 minutes to just tokenize 100000 notes.',\n",
       " 'This is kind of annoying if you are playing with hyperparameters of a Vectorizer for your NLP Bag-of-words model.',\n",
       " 'Note that the cleaning function plays a minimal role with this tokenizer (12 seconds out of 291 seconds).',\n",
       " 'Let’s see if we can do better.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing Sentences\n",
    "sentences = nltk.sent_tokenize(program)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing words\n",
    "word = nltk.word_tokenize(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Well',\n",
       " 'that',\n",
       " '’',\n",
       " 's',\n",
       " 'just',\n",
       " 'disappointing',\n",
       " ':',\n",
       " 'it',\n",
       " 'takes',\n",
       " '5',\n",
       " 'minutes',\n",
       " 'to',\n",
       " 'just',\n",
       " 'tokenize',\n",
       " '100000',\n",
       " 'notes',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'annoying',\n",
       " 'if',\n",
       " 'you',\n",
       " 'are',\n",
       " 'playing',\n",
       " 'with',\n",
       " 'hyperparameters',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Vectorizer',\n",
       " 'for',\n",
       " 'your',\n",
       " 'NLP',\n",
       " 'Bag-of-words',\n",
       " 'model',\n",
       " '.',\n",
       " 'Note',\n",
       " 'that',\n",
       " 'the',\n",
       " 'cleaning',\n",
       " 'function',\n",
       " 'plays',\n",
       " 'a',\n",
       " 'minimal',\n",
       " 'role',\n",
       " 'with',\n",
       " 'this',\n",
       " 'tokenizer',\n",
       " '(',\n",
       " '12',\n",
       " 'seconds',\n",
       " 'out',\n",
       " 'of',\n",
       " '291',\n",
       " 'seconds',\n",
       " ')',\n",
       " '.',\n",
       " 'Let',\n",
       " '’',\n",
       " 's',\n",
       " 'see',\n",
       " 'if',\n",
       " 'we',\n",
       " 'can',\n",
       " 'do',\n",
       " 'better',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
