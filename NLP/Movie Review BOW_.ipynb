{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sentiment Analysis for Movie Review <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('movie-Review.csv')\n",
    "df_or = pd.read_csv('movie-Review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Neg</td>\n",
       "      <td>billy bob thornton   who had a sudden rise to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                               text\n",
       "count   2000                                               2000\n",
       "unique     2                                               2000\n",
       "top      Neg   billy bob thornton   who had a sudden rise to...\n",
       "freq    1000                                                  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      "class    2000 non-null object\n",
      "text     2000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   Pos   films adapted from comic books have had plent...\n",
       "1   Pos   every now and then a movie comes along from a...\n",
       "2   Pos   you ve got mail works alot better than it des...\n",
       "3   Pos      jaws   is a rare film that grabs your atte...\n",
       "4   Pos   moviemaking is a lot like being the general m..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAW5UlEQVR4nO3de7QlZX3m8e9jtyjeuEjjYAM2ak+UoCHYEpWgjiijoEBYEFEnEmTEyeAFlYxoHPGSWYpRUWYSIgEUjSMCIYqKIIOK7ajc76DSQYUOjLQLBPECtvzmj3pP2J4+fWpD995nd5/vZ629dtVb7971616n+zlVb9VbqSokSZrNQ+a6AEnS5DMsJEm9DAtJUi/DQpLUy7CQJPVaONcFjMJWW21VS5YsmesyJGmDcumll/60qhbNtG2jDIslS5ZwySWXzHUZkrRBSfLjtW3zNJQkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6jWysEhycpLbklwz0LZlkvOS3NDet2jtSXJckhVJrkqyy8BnDm79b0hy8KjqlSSt3SiPLD4JvHha21HA+VW1FDi/rQO8BFjaXocBx0MXLsDRwB8BuwJHTwWMJGl8RhYWVfVN4PZpzfsCp7TlU4D9Bto/VZ3vApsn2Qb4j8B5VXV7Vd0BnMeaASRJGrFx38H9uKq6FaCqbk2ydWtfDNw80G9la1tb+xqSHEZ3VML222+/TkUuOerL6/R5bbx+9IG957oEwJ9Rrd2ofkYnZYA7M7TVLO1rNladUFXLqmrZokUzTm0iSXqQxh0WP2mnl2jvt7X2lcB2A/22BW6ZpV2SNEbjDouzgKkrmg4GvjDQ/up2VdSzgDvb6apzgT2TbNEGtvdsbZKkMRrZmEWSzwLPB7ZKspLuqqYPAKclORS4CTiwdT8b2AtYAfwSOASgqm5P8j7g4tbvvVU1fdBckjRiIwuLqnrFWjbtMUPfAg5fy/ecDJy8HkuTJD1AkzLALUmaYIaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSes1JWCR5c5Jrk1yT5LNJHp5khyQXJrkhyeeSbNL6Pqytr2jbl8xFzZI0n409LJIsBt4ILKuqnYAFwEHAMcCxVbUUuAM4tH3kUOCOqnoycGzrJ0kao7k6DbUQ2DTJQuARwK3AC4Az2vZTgP3a8r5tnbZ9jyQZY62SNO+NPSyq6l+BDwE30YXEncClwM+qanXrthJY3JYXAze3z65u/R87/XuTHJbkkiSXrFq1arR/CEmaZ+biNNQWdEcLOwCPBx4JvGSGrjX1kVm23d9QdUJVLauqZYsWLVpf5UqSmJvTUC8EflhVq6rqN8CZwHOAzdtpKYBtgVva8kpgO4C2fTPg9vGWLEnz21yExU3As5I8oo097AFcB3wdOKD1ORj4Qls+q63Ttn+tqtY4spAkjc5cjFlcSDdQfRlwdavhBOBtwFuSrKAbkzipfeQk4LGt/S3AUeOuWZLmu4X9Xda/qjoaOHpa843ArjP0/TVw4DjqkiTNzDu4JUm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1Ks3LJK8JsnScRQjSZpMw9yUtwT4T0meQDc77HJgeVVdMcrCJEmTo/fIoqreVVUvAHYCvgX8JV1oSJLmid4jiyTvBHYDHgVcDhxJd3QhSZonhjkNtT+wGvgycAHw3TZfkyRpnhjmNNQudNOIXwS8CLg6ybdGXZgkaXIMcxpqJ2B34HnAMrpHnHoaSpLmkWFOQx0DfBM4Dri4Pd1OkjSP9IZFVe2dZFNge4NCkuanYW7KexlwBXBOW985yVmjLkySNDmGme7j3XRPsPsZQLsZb8noSpIkTZphwmJ1Vd058kokSRNrmAHua5K8EljQ5oh6I/Dt0ZYlSZokwxxZvAH4feAe4LPAXcARoyxKkjRZhrka6pfAX7WXJGkeWmtYJPloVR2R5ItATd9eVfuMtDJJ0sSY7cji0+39Q+MoRJI0udYaFlU1NQ35lsDZVXXPeEqSJE2aYQa49wF+kOTTSfZOMswVVJKkjcgws84eAjwZOB14JfAvSU4cdWGSpMkx1FFCVf0myVfoBro3BfYF/vMoC5MkTY5h5oZ6cZJPAiuAA4ATgW1GXJckaYIMc2Tx58CpwOsc5Jak+WmYMYuD6J69vTtAkk2TPHrUhUmSJscwp6FeC5wBfLw1bQt8fpRFSZImyzCXzh4O7EY3JxRVdQOw9brsNMnmSc5I8r0k1yd5dpItk5yX5Ib2vkXrmyTHJVmR5Koku6zLviVJD9wwYXFPVd07tdLus1hj+o8H6GPAOVX1FOAPgOuBo4Dzq2opcH5bB3gJsLS9DgOOX8d9S5IeoGHC4oIk7wA2TfIiuvstvvhgd5jkMcBzgZMAqureqvoZ3eW4p7RupwD7teV9gU9V57vA5km8GkuSxmiYsDgKWAVcDbwOOBt45zrs84nt+z6R5PIkJyZ5JPC4qroVoL1PnepaDNw88PmVrU2SNCbDXA11X1X9Q1UdWFUHVNU/AM9Zh30uBHYBjq+qPwR+wf2nnGaSmcpao1NyWJJLklyyatWqdShPkjTdWsMiyYIkr0hyZJKdWttLk3wb+F/rsM+VwMqqurCtn0EXHj+ZOr3U3m8b6L/dwOe3BW6Z/qVVdUJVLauqZYsWLVqH8iRJ0812ZHES3ZQejwWOS/IJuunKP9iOCB6Uqvp/wM1Jfq817QFcB5wFHNzaDga+0JbPAl7drop6FnDn1OkqSdJ4zHYH9zLg6VV1X5KHAz8Fntz+s19XbwA+k2QT4EbgELrgOi3JocBNwIGt79nAXnTTjfyy9ZUkjdFsYXFvVd0HUFW/TvKD9RQUVNUVdGE03R4z9C26ez0kSXNktrB4SpKr2nKAJ7X10P0f/vSRVydJmgizhcVTx1aFJGmizfZY1R+PsxBJ0uQa5qY8SdI8Z1hIknrNdlPe+e39mPGVI0maRLMNcG+T5HnAPklOZdq0G1V12UgrkyRNjNnC4l10czZtC3xk2rYCXjCqoiRJk2W2q6HOAM5I8t+r6n1jrEmSNGFmO7IAoKrel2QfumdQAHyjqr402rIkSZNkmGdwvx94E91kf9cBb2ptkqR5ovfIAtgb2HlqnqgkpwCXA28fZWGSpMkx7H0Wmw8sbzaKQiRJk2uYI4v3A5cn+Trd5bPPxaMKSZpXhhng/mySbwDPpAuLt62vqcolSRuGYY4saE+mO2vEtUiSJpRzQ0mSehkWkqRes4ZFkockuWZcxUiSJtOsYdHurbgyyfZjqkeSNIGGGeDeBrg2yUXAL6Yaq2qfkVUlSZoow4TFe0ZehSRpog1zn8UFSZ4ALK2q/5PkEcCC0ZcmSZoUw0wk+FrgDODjrWkx8PlRFiVJmizDXDp7OLAbcBdAVd0AbD3KoiRJk2WYsLinqu6dWkmykO5JeZKkeWKYsLggyTuATZO8CDgd+OJoy5IkTZJhwuIoYBVwNfA64GzgnaMsSpI0WYa5Guq+9sCjC+lOP32/qjwNJUnzSG9YJNkb+HvgX+imKN8hyeuq6iujLk6SNBmGuSnvw8B/qKoVAEmeBHwZMCwkaZ4YZszitqmgaG4EbhtRPZKkCbTWI4sk+7fFa5OcDZxGN2ZxIHDxGGqTJE2I2Y4sXtZeDwd+AjwPeD7dlVFbrOuOkyxIcnmSL7X1HZJcmOSGJJ9Lsklrf1hbX9G2L1nXfUuSHpi1HllU1SEj3vebgOuBx7T1Y4Bjq+rUJH8PHAoc397vqKonJzmo9Xv5iGuTJA0YZm6oHZJ8JMmZSc6aeq3LTpNsC+wNnNjWA7yAbg4qgFOA/dryvm2dtn2P1l+SNCbDXA31eeAkuru271tP+/0o8N+AR7f1xwI/q6rVbX0l3YSFtPebAapqdZI7W/+fDn5hksOAwwC2395nNUnS+jRMWPy6qo5bXztM8lK6K6wuTfL8qeYZutYQ2+5vqDoBOAFg2bJl3jQoSevRMGHxsSRHA18F7plqrKrLHuQ+dwP2SbIX3eD5Y+iONDZPsrAdXWwL3NL6rwS2A1a2SQw3A25/kPuWJD0Iw4TF04A/oxtTmDoNVW39AauqtwNvB2hHFkdW1auSnA4cAJwKHAx8oX3krLb+nbb9a043IknjNUxY/AnwxMFpykfkbcCpSf4auJxunIT2/ukkK+iOKA4acR2SpGmGCYsrgc0ZwV3bVfUN4Btt+UZg1xn6/JruRkBJ0hwZJiweB3wvycX87pjFPiOrSpI0UYYJi6NHXoUkaaIN8zyLC8ZRiCRpcg3zPIufc/99DZsADwV+UVWPWfunJEkbk2GOLB49uJ5kP2YYiJYkbbyGeZ7F76iqz/Mg77GQJG2YhjkNtf/A6kOAZcww3YYkaeM1zNVQLxtYXg38iG4mWEnSPDHMmMWon2shSZpwsz1W9V2zfK6q6n0jqEeSNIFmO7L4xQxtj6R7ct1jAcNCkuaJ2R6r+uGp5SSPpnsM6iF0s8J+eG2fkyRtfGYds0iyJfAW4FV0jzbdparuGEdhkqTJMduYxd8A+9M9fe5pVXX32KqSJE2U2W7KeyvweOCdwC1J7mqvnye5azzlSZImwWxjFg/47m5J0sbJQJAk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJAk9TIsJEm9DAtJUi/DQpLUa+xhkWS7JF9Pcn2Sa5O8qbVvmeS8JDe09y1ae5Icl2RFkquS7DLumiVpvpuLI4vVwFur6qnAs4DDk+wIHAWcX1VLgfPbOsBLgKXtdRhw/PhLlqT5bexhUVW3VtVlbfnnwPXAYmBf4JTW7RRgv7a8L/Cp6nwX2DzJNmMuW5LmtTkds0iyBPhD4ELgcVV1K3SBAmzdui0Gbh742MrWNv27DktySZJLVq1aNcqyJWnembOwSPIo4J+AI6rqrtm6ztBWazRUnVBVy6pq2aJFi9ZXmZIk5igskjyULig+U1VntuafTJ1eau+3tfaVwHYDH98WuGVctUqS5uZqqAAnAddX1UcGNp0FHNyWDwa+MND+6nZV1LOAO6dOV0mSxmPhHOxzN+DPgKuTXNHa3gF8ADgtyaHATcCBbdvZwF7ACuCXwCHjLVeSNPawqKpvMfM4BMAeM/Qv4PCRFiVJmpV3cEuSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6bTBhkeTFSb6fZEWSo+a6HkmaTzaIsEiyAPhb4CXAjsArkuw4t1VJ0vyxQYQFsCuwoqpurKp7gVOBfee4JkmaNxbOdQFDWgzcPLC+EvijwQ5JDgMOa6t3J/n+mGrb2G0F/HSui5gUOWauK9AM/BkdsI4/o09Y24YNJSwyQ1v9zkrVCcAJ4yln/khySVUtm+s6pLXxZ3Q8NpTTUCuB7QbWtwVumaNaJGne2VDC4mJgaZIdkmwCHAScNcc1SdK8sUGchqqq1UleD5wLLABOrqpr57is+cJTe5p0/oyOQaqqv5ckaV7bUE5DSZLmkGEhSeplWMxjSSrJhwfWj0zy7jksSZpRkt8muSLJNUlOT/KIua5pvjEs5rd7gP2TbDXXhUg9flVVO1fVTsC9wH+Z64LmG8NifltNdyXJm6dvSLIoyT8lubi9dhtoPy/JZUk+nuTHho3GbDnwZIAkb2lHG9ckOaK1PTLJl5Nc2dpfPqfVbiQ2iEtnNVJ/C1yV5IPT2j8GHFtV30qyPd1ly08Fjga+VlXvT/Ji7p9iRRq5JAvpJhQ9J8kzgEPopv4JcGGSC4AnArdU1d7tM5vNVb0bE8Ninququ5J8Cngj8KuBTS8Edkz+baaVxyR5NPDHwJ+0z56T5I5x1qt5a9MkV7Tl5cBJwF8A/1xVvwBIciawO3AO8KEkxwBfqqrlc1HwxsawEMBHgcuATwy0PQR4dlUNBggZSA9pjH5VVTsPNqztZ7GqftCOOvYC3p/kq1X13nEUuTFzzEJU1e3AacChA81fBV4/tZJk6h/qt4A/bW17AluMqUxpum8C+yV5RJJH0h3xLk/yeOCXVfWPwIeAXeayyI2FYaEpH6ab6nnKG4FlSa5Kch33X33yHmDPJJfRnTu+Ffj5WCuVgKq6DPgkcBFwIXBiVV0OPA24qJ22+ivgr+esyI2I033oAUnyMOC3bb6uZwPHTz89IGnj45iFHqjtgdOSPITuevfXznE9ksbAIwtJUi/HLCRJvQwLSVIvw0KS1Muw0AZp2iykX0yy+YP8nscnOWM91/aaJFe3y46vSbLvg/yeJUleObC+LMlx66/SGfe5c5K9RrkPbZgc4NYGKcndVfWotnwK8IOq+h9zXBZJtgUuAHapqjuTPApYVFU/fBDf9XzgyKp66Xouc7Z9/jmwrKpe39dX84tHFtoYfAdYPLWS5C/bTLlXJXlPazsmyX8d6PPuJG9tv71f09oWJPmbgc++rrX/XZJ92vI/Jzm5LR+aZPoNX1vT3aR4N0BV3T0VFEmelOScJJcmWZ7kKa39k0mOS/LtJDcmOaB91weA3dsR1JuTPD/JlwbqPyXJV5P8KMn+ST7YjmjOSfLQ1u8ZSS5o+zw3yTat/Rvt7+SiJD9IsnuSTYD3Ai9v+3x5kue15SuSXN7mB9M8ZFhog5ZkAbAHcFZb3xNYCuwK7Aw8I8lzgVOBwamq/xQ4fdrXHQrcWVXPBJ4JvDbJDnTTSuze+iwGdmzLf0w3qd2gK4GfAD9M8okkLxvYdgLwhqp6BnAk8HcD27Zp3/dSupAAOApY3p7jcOwMf/wnAXsD+wL/CHy9qp5GNyHk3i0w/idwQNvnycDg0dfCqtoVOAI4uqruBd4FfK7t83OtzsPbjZe787uTTWoe8aY8baimZiFdAlwKnNfa92yvy9v6o4ClVXVSkq3bvEGLgDuq6qYkSwa+c0/g6QO/2W9GFzzLgSOS7AhcB2zRfkN/Nt20KP+mqn6bbur2Z9KF2LFtUrsPAc8BTh+Y/+5hAx/9fFXdB1yX5HFD/h18pap+k+RqYAHdbKsAV7e/l98DdgLOa/tcQDc9y5Qz2/ulrf9M/i/wkSSfAc6sqpVD1qaNjGGhDdWvqmrndM8q+BJwOHAc3XMN3l9VH5/hM2cABwD/ju5IY7rQ/eZ/7hobki2AF9MdZWxJd2Ryd1WtMS9WdQOBF9HNT3Qe3Wy+HwF+NsvUKPdMq2MY97T93ZfkN3X/AOR9dP+2A1xbVc/u2edvWcv/BVX1gSRfppvB9btJXlhV3xuyPm1EPA2lDVpV3Un32/2R7bTLucBr2sAySRYn2bp1PxU4iC4wZroC6lzgLwbO9//7dLOZQjcucgRdWCynOz2zxnMS2tVVg7Oc7gz8uKruojs1dWDrlyR/0PPH+zmwLmME3wcWpZvDiyQPTfL7D2SfSZ5UVVdX1THAJcBT1qEebcAMC23w2kyjVwIHVdVXgf8NfKednjmD9p9fVV3blv+1qm6d4atOpDvNdFkb9P449//GvZzuHP8Kumd/bMkMYQE8lO7BO99rp8leDrypbXsVcGiSK4Fr6cYaZnMVsDrd40HXePRtnzYGcQBwTNvnFXSnwmbzdbqHXl2R7nGkR6S7/PdKuvGKrzzQOrRx8NJZSVIvjywkSb0MC0lSL8NCktTLsJAk9TIsJEm9DAtJUi/DQpLU6/8DW50QhfSnvk0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_count=df.groupby('class').count()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(class_count.index.values, class_count['text'])\n",
    "plt.xlabel('Review Sentiments')\n",
    "plt.ylabel('Number of Review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Text Pre – processing¶\n",
    "Load the sample.txt data in to python environment\n",
    "Remove numbers using regex\n",
    "Remove punctuations\n",
    "Convert all the words in to lower case\n",
    "Do word tokenization\n",
    "Remove all stop words\n",
    "Do lemmatization with pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pos</td>\n",
       "      <td>on june       a self taught   idealistic   ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pos</td>\n",
       "      <td>apparently   director tony kaye had a major b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pos</td>\n",
       "      <td>one of my colleagues was surprised when i tol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pos</td>\n",
       "      <td>after bloody clashes and independence won   l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pos</td>\n",
       "      <td>the american action film has been slowly drow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   Pos   films adapted from comic books have had plent...\n",
       "1   Pos   every now and then a movie comes along from a...\n",
       "2   Pos   you ve got mail works alot better than it des...\n",
       "3   Pos      jaws   is a rare film that grabs your atte...\n",
       "4   Pos   moviemaking is a lot like being the general m...\n",
       "5   Pos   on june       a self taught   idealistic   ye...\n",
       "6   Pos   apparently   director tony kaye had a major b...\n",
       "7   Pos   one of my colleagues was surprised when i tol...\n",
       "8   Pos   after bloody clashes and independence won   l...\n",
       "9   Pos   the american action film has been slowly drow..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove number\n",
    "import re # import all Regular expression functions\n",
    "df['text']=[re.sub('\\d','', i)for i in df['text']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pos</td>\n",
       "      <td>on june       a self taught   idealistic   ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pos</td>\n",
       "      <td>apparently   director tony kaye had a major b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pos</td>\n",
       "      <td>one of my colleagues was surprised when i tol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pos</td>\n",
       "      <td>after bloody clashes and independence won   l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pos</td>\n",
       "      <td>the american action film has been slowly drow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   Pos   films adapted from comic books have had plent...\n",
       "1   Pos   every now and then a movie comes along from a...\n",
       "2   Pos   you ve got mail works alot better than it des...\n",
       "3   Pos      jaws   is a rare film that grabs your atte...\n",
       "4   Pos   moviemaking is a lot like being the general m...\n",
       "5   Pos   on june       a self taught   idealistic   ye...\n",
       "6   Pos   apparently   director tony kaye had a major b...\n",
       "7   Pos   one of my colleagues was surprised when i tol...\n",
       "8   Pos   after bloody clashes and independence won   l...\n",
       "9   Pos   the american action film has been slowly drow..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace punctuations with a white space\n",
    "import string\n",
    "df['text']=[re.sub('[%s]' % re.escape(string.punctuation), ' ', i) for i in df['text']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert in lower case\n",
    "df['text']=[i.lower() for i in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "      <td>[films, adapted, from, comic, books, have, had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "      <td>[every, now, and, then, a, movie, comes, along...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "      <td>[you, ve, got, mail, works, alot, better, than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "      <td>[jaws, is, a, rare, film, that, grabs, your, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "      <td>[moviemaking, is, a, lot, like, being, the, ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text  \\\n",
       "0   Pos   films adapted from comic books have had plent...   \n",
       "1   Pos   every now and then a movie comes along from a...   \n",
       "2   Pos   you ve got mail works alot better than it des...   \n",
       "3   Pos      jaws   is a rare film that grabs your atte...   \n",
       "4   Pos   moviemaking is a lot like being the general m...   \n",
       "\n",
       "                                             text_wt  \n",
       "0  [films, adapted, from, comic, books, have, had...  \n",
       "1  [every, now, and, then, a, movie, comes, along...  \n",
       "2  [you, ve, got, mail, works, alot, better, than...  \n",
       "3  [jaws, is, a, rare, film, that, grabs, your, a...  \n",
       "4  [moviemaking, is, a, lot, like, being, the, ge...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd \n",
    "import pandas as pd \n",
    "#Word Tokenization\n",
    "import nltk # import package for tokenization\n",
    "#nltk.download('punkt') # download all spporting function /files for NLTK package\n",
    "from nltk.tokenize import word_tokenize\n",
    "df['text_wt'] = [word_tokenize(i) for i in df['text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wt</th>\n",
       "      <th>text_SW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "      <td>[films, adapted, from, comic, books, have, had...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "      <td>[every, now, and, then, a, movie, comes, along...</td>\n",
       "      <td>[every, movie, comes, along, suspect, studio, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "      <td>[you, ve, got, mail, works, alot, better, than...</td>\n",
       "      <td>[got, mail, works, alot, better, deserves, ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "      <td>[jaws, is, a, rare, film, that, grabs, your, a...</td>\n",
       "      <td>[jaws, rare, film, grabs, attention, shows, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "      <td>[moviemaking, is, a, lot, like, being, the, ge...</td>\n",
       "      <td>[moviemaking, lot, like, general, manager, nfl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text  \\\n",
       "0   Pos   films adapted from comic books have had plent...   \n",
       "1   Pos   every now and then a movie comes along from a...   \n",
       "2   Pos   you ve got mail works alot better than it des...   \n",
       "3   Pos      jaws   is a rare film that grabs your atte...   \n",
       "4   Pos   moviemaking is a lot like being the general m...   \n",
       "\n",
       "                                             text_wt  \\\n",
       "0  [films, adapted, from, comic, books, have, had...   \n",
       "1  [every, now, and, then, a, movie, comes, along...   \n",
       "2  [you, ve, got, mail, works, alot, better, than...   \n",
       "3  [jaws, is, a, rare, film, that, grabs, your, a...   \n",
       "4  [moviemaking, is, a, lot, like, being, the, ge...   \n",
       "\n",
       "                                             text_SW  \n",
       "0  [films, adapted, comic, books, plenty, success...  \n",
       "1  [every, movie, comes, along, suspect, studio, ...  \n",
       "2  [got, mail, works, alot, better, deserves, ord...  \n",
       "3  [jaws, rare, film, grabs, attention, shows, si...  \n",
       "4  [moviemaking, lot, like, general, manager, nfl...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#To show the stop words\n",
    "#nltk.download('stopwords') #download Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#Remove All Stop Word\n",
    "df['text_SW'] = [[i for i in j if not i in stop_words] for j in df['text_wt']]# remove the word which is aviable in stopword libr\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('tagsets')\n",
    "#nltk.help.upenn_tagset()# tagset documentation\n",
    "#nltk.download('wordnet')\n",
    "from collections import defaultdict #Default Dictionary is imported from collections\n",
    "from nltk.corpus import wordnet as wn #the corpus reader wordnet is imported.\n",
    "from nltk.tag import pos_tag\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. \n",
    "#By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN) #Dictionary is created where pos_tag (first letter) are the key values \n",
    "tag_map['J'] = wn.ADJ                   #whose values are mapped with the value \n",
    "tag_map['V'] = wn.VERB                  #from wordnet dictionary. We have taken the only first letter as \n",
    "tag_map['R'] = wn.ADV\n",
    "# we will use it later in the loop.\n",
    "#tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wt</th>\n",
       "      <th>text_SW</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "      <td>[films, adapted, from, comic, books, have, had...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "      <td>[film, adapt, comic, book, plenty, success, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "      <td>[every, now, and, then, a, movie, comes, along...</td>\n",
       "      <td>[every, movie, comes, along, suspect, studio, ...</td>\n",
       "      <td>[every, movie, come, along, suspect, studio, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "      <td>[you, ve, got, mail, works, alot, better, than...</td>\n",
       "      <td>[got, mail, works, alot, better, deserves, ord...</td>\n",
       "      <td>[get, mail, work, alot, good, deserves, order,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "      <td>[jaws, is, a, rare, film, that, grabs, your, a...</td>\n",
       "      <td>[jaws, rare, film, grabs, attention, shows, si...</td>\n",
       "      <td>[jaw, rare, film, grab, attention, show, singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "      <td>[moviemaking, is, a, lot, like, being, the, ge...</td>\n",
       "      <td>[moviemaking, lot, like, general, manager, nfl...</td>\n",
       "      <td>[moviemaking, lot, like, general, manager, nfl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text  \\\n",
       "0   Pos   films adapted from comic books have had plent...   \n",
       "1   Pos   every now and then a movie comes along from a...   \n",
       "2   Pos   you ve got mail works alot better than it des...   \n",
       "3   Pos      jaws   is a rare film that grabs your atte...   \n",
       "4   Pos   moviemaking is a lot like being the general m...   \n",
       "\n",
       "                                             text_wt  \\\n",
       "0  [films, adapted, from, comic, books, have, had...   \n",
       "1  [every, now, and, then, a, movie, comes, along...   \n",
       "2  [you, ve, got, mail, works, alot, better, than...   \n",
       "3  [jaws, is, a, rare, film, that, grabs, your, a...   \n",
       "4  [moviemaking, is, a, lot, like, being, the, ge...   \n",
       "\n",
       "                                             text_SW  \\\n",
       "0  [films, adapted, comic, books, plenty, success...   \n",
       "1  [every, movie, comes, along, suspect, studio, ...   \n",
       "2  [got, mail, works, alot, better, deserves, ord...   \n",
       "3  [jaws, rare, film, grabs, attention, shows, si...   \n",
       "4  [moviemaking, lot, like, general, manager, nfl...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [film, adapt, comic, book, plenty, success, wh...  \n",
       "1  [every, movie, come, along, suspect, studio, e...  \n",
       "2  [get, mail, work, alot, good, deserves, order,...  \n",
       "3  [jaw, rare, film, grab, attention, show, singl...  \n",
       "4  [moviemaking, lot, like, general, manager, nfl...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization\n",
    "from nltk.stem import WordNetLemmatizer \n",
    " # Initializing WordNetLemmatizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['lemma']=[[lemmatizer.lemmatize(word,tag_map[tag[0]]) for word ,tag in pos_tag(i)] for i in df['text_SW']] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " df['lemma2']= df['lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    film adapt comic book plenty success whether s...\n",
       "1    every movie come along suspect studio every in...\n",
       "2    get mail work alot good deserves order make fi...\n",
       "3    jaw rare film grab attention show single image...\n",
       "4    moviemaking lot like general manager nfl team ...\n",
       "Name: lemma2, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemma2'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Test_X, Train_Y1, Test_Y1 = train_test_split(df['lemma2'],df['class'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83      Pos\n",
       "885     Pos\n",
       "1725    Neg\n",
       "660     Pos\n",
       "1776    Neg\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Y1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode the target variable — This is done to transform Categorical data of string type in the data set into numerical values which the model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313    Neg\n",
      "330     Pos\n",
      "1923    Neg\n",
      "760     Pos\n",
      "Name: class, dtype: object\n",
      "[0 1 0 1]\n",
      "885     Pos\n",
      "1725    Neg\n",
      "660     Pos\n",
      "1776    Neg\n",
      "Name: class, dtype: object\n",
      "[1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y1)\n",
    "Test_Y = Encoder.fit_transform(Test_Y1)\n",
    "print(Train_Y1[1:5])\n",
    "print(Train_Y[1:5])\n",
    "print(Test_Y1[1:5])\n",
    "print(Test_Y[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958     calendar year even reach midway point prevent ...\n",
       "1313    let begin say easily bad movie entire official...\n",
       "330     one never quite know one go get mamet film ame...\n",
       "1923    first species moderately successful science fi...\n",
       "760     italian hitchcock acknowledge master giallo mu...\n",
       "Name: lemma2, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#instantiate CountVectorizer()# CountVectorizer to count the number of words (term frequency)\n",
    "cv = CountVectorizer(max_features=5000) \n",
    "#this steps generates word counts for the words in your docs and return term-document matrix.\n",
    "Train_X_BOW = cv.fit_transform(Train_X).toarray()\n",
    "Test_X_BOW = cv.fit_transform(Test_X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorb</th>\n",
       "      <th>...</th>\n",
       "      <th>zahn</th>\n",
       "      <th>zane</th>\n",
       "      <th>zany</th>\n",
       "      <th>zellweger</th>\n",
       "      <th>zemeckis</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoolander</th>\n",
       "      <th>zwick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  ability  able  aboard  abraham  absence  absent  absolute  \\\n",
       "0        0        0     0       0        0        0       0         0   \n",
       "1        0        0     0       0        0        0       0         0   \n",
       "2        0        0     0       0        0        0       0         0   \n",
       "3        0        0     1       1        0        0       0         0   \n",
       "4        0        0     0       0        0        0       0         0   \n",
       "\n",
       "   absolutely  absorb  ...  zahn  zane  zany  zellweger  zemeckis  zero  zeta  \\\n",
       "0           0       0  ...     2     0     0          0         0     0     0   \n",
       "1           0       0  ...     0     0     0          0         0     0     0   \n",
       "2           0       0  ...     1     0     0          0         0     0     0   \n",
       "3           0       1  ...     0     0     0          0         0     0     0   \n",
       "4           0       0  ...     0     0     0          0         0     0     0   \n",
       "\n",
       "   zone  zoolander  zwick  \n",
       "0     0          0      0  \n",
       "1     0          0      0  \n",
       "2     0          0      0  \n",
       "3     0          0      0  \n",
       "4     0          0      0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Train_X_BOW, columns=cv.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorb</th>\n",
       "      <th>...</th>\n",
       "      <th>zahn</th>\n",
       "      <th>zane</th>\n",
       "      <th>zany</th>\n",
       "      <th>zellweger</th>\n",
       "      <th>zemeckis</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoolander</th>\n",
       "      <th>zwick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  ability  able  aboard  abraham  absence  absent  absolute  \\\n",
       "0        0        0     0       0        0        0       0         0   \n",
       "1        0        0     0       0        0        0       0         0   \n",
       "2        0        0     0       0        0        0       0         0   \n",
       "3        0        0     0       0        0        1       0         0   \n",
       "4        0        1     0       1        0        0       0         0   \n",
       "\n",
       "   absolutely  absorb  ...  zahn  zane  zany  zellweger  zemeckis  zero  zeta  \\\n",
       "0           0       0  ...     0     0     0          0         0     0     0   \n",
       "1           0       1  ...     0     0     0          0         0     0     0   \n",
       "2           0       0  ...     0     0     0          0         0     0     0   \n",
       "3           0       0  ...     0     0     0          0         0     0     0   \n",
       "4           0       0  ...     0     0     0          0         0     0     0   \n",
       "\n",
       "   zone  zoolander  zwick  \n",
       "0     0          0      0  \n",
       "1     0          0      0  \n",
       "2     0          0      0  \n",
       "3     0          0      0  \n",
       "4     0          0      0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Test_X_BOW, columns=cv.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 54.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Generation Using Multinomial Naive Bayes\n",
    "clf = MultinomialNB().fit(Train_X_BOW, Train_Y)\n",
    "predicted= clf.predict(Test_X_BOW)\n",
    "print(\"MultinomialNB Accuracy:\",round(accuracy_score(predicted,Test_Y)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  55.33 %\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_BOW,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_BOW)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",round(accuracy_score(predictions_SVM, Test_Y)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=501,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification \n",
    "# to the Training set \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# n_estimators can be said as number of \n",
    "# trees, experiment with n_estimators \n",
    "# to get better results \n",
    "model = RandomForestClassifier(n_estimators = 501, criterion = 'entropy') \n",
    "model.fit(Train_X_BOW, Train_Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results \n",
    "y_pred = model.predict(Test_X_BOW) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest Accuracy Score ->  55.17 %\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(Test_Y, y_pred) \n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Random forest Accuracy Score -> \",round(accuracy_score(y_pred, Test_Y)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
