{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre â€“ processing \n",
    "1.\tLoad the sample.txt data in to python environment\n",
    "2.\tRemove numbers using regex\n",
    "3.\tRemove punctuations\n",
    "4.\tConvert all the words in to lower case\n",
    "5.\tDo word tokenization\n",
    "6.\tRemove all stop words\n",
    "7.\tApply stemming\n",
    "8.\tDo lemmatization with pos tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.  He was ever dusting his old lexicons and grammars, with a queer\n",
      "handkerchief, mockingly embellished with all the gay flags of all the\n",
      "known nations of the world.  He loved to dust his old grammars; it\n",
      "somehow mildly reminded him of his mortality.\n",
      "\"While you take in hand to school others, and to teach them by what\n",
      "name a whale-fish is to be called in our tongue leaving out, through\n",
      "ignorance, the letter H, which almost alone maketh the signification\n",
      "of the word, you deliver that which is not true.\" --HACKLUYT\n",
      "\"Myself have agreed to try whether I can master and kill this\n",
      "Sperma-ceti whale, for I could never hear of any of that sort that\n",
      "was killed by any man, such is his fierceness and swiftness.\"\n",
      "--RICHARD STRAFFORD'S LETTER FROM THE BERMUDAS.  PHIL. TRANS.  A.D.\n",
      "1668.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import text file\n",
    "#File_object = open(r\"File_Name\",\"Access_Mode\")\n",
    "input_file = open(r\"C:\\Users\\shashi.singh\\NLP video\\NLP_Shashi\\Sample.txt\",\"r\").read()\n",
    "print(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.  He was ever dusting his old lexicons and grammars, with a queer\n",
      "handkerchief, mockingly embellished with all the gay flags of all the\n",
      "known nations of the world.  He loved to dust his old grammars; it\n",
      "somehow mildly reminded him of his mortality.\n",
      "\"While you take in hand to school others, and to teach them by what\n",
      "name a whale-fish is to be called in our tongue leaving out, through\n",
      "ignorance, the letter H, which almost alone maketh the signification\n",
      "of the word, you deliver that which is not true.\" --HACKLUYT\n",
      "\"Myself have agreed to try whether I can master and kill this\n",
      "Sperma-ceti whale, for I could never hear of any of that sort that\n",
      "was killed by any man, such is his fierceness and swiftness.\"\n",
      "--RICHARD STRAFFORD'S LETTER FROM THE BERMUDAS.  PHIL. TRANS.  A.D.\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Remove number\n",
    "import re # import all Regular expression functions\n",
    "input_file1=re.sub('\\d','',input_file)\n",
    "print(input_file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pale Usher  threadbare in coat  heart  body  and brain  I see him\n",
      "now   He was ever dusting his old lexicons and grammars  with a queer\n",
      "handkerchief  mockingly embellished with all the gay flags of all the\n",
      "known nations of the world   He loved to dust his old grammars  it\n",
      "somehow mildly reminded him of his mortality \n",
      " While you take in hand to school others  and to teach them by what\n",
      "name a whale fish is to be called in our tongue leaving out  through\n",
      "ignorance  the letter H  which almost alone maketh the signification\n",
      "of the word  you deliver that which is not true     HACKLUYT\n",
      " Myself have agreed to try whether I can master and kill this\n",
      "Sperma ceti whale  for I could never hear of any of that sort that\n",
      "was killed by any man  such is his fierceness and swiftness  \n",
      "  RICHARD STRAFFORD S LETTER FROM THE BERMUDAS   PHIL  TRANS   A D \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace punctuations with a white space\n",
    "import string\n",
    "input_file2=re.sub('[%s]' % re.escape(string.punctuation), ' ', input_file1)\n",
    "print(input_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pale usher  threadbare in coat  heart  body  and brain  i see him\n",
      "now   he was ever dusting his old lexicons and grammars  with a queer\n",
      "handkerchief  mockingly embellished with all the gay flags of all the\n",
      "known nations of the world   he loved to dust his old grammars  it\n",
      "somehow mildly reminded him of his mortality \n",
      " while you take in hand to school others  and to teach them by what\n",
      "name a whale fish is to be called in our tongue leaving out  through\n",
      "ignorance  the letter h  which almost alone maketh the signification\n",
      "of the word  you deliver that which is not true     hackluyt\n",
      " myself have agreed to try whether i can master and kill this\n",
      "sperma ceti whale  for i could never hear of any of that sort that\n",
      "was killed by any man  such is his fierceness and swiftness  \n",
      "  richard strafford s letter from the bermudas   phil  trans   a d \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert in Lower Case\n",
    "input_file3=input_file2.lower()\n",
    "print(input_file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'pale', 'usher', 'threadbare', 'in', 'coat', 'heart', 'body', 'and', 'brain', 'i', 'see', 'him', 'now', 'he', 'was', 'ever', 'dusting', 'his', 'old', 'lexicons', 'and', 'grammars', 'with', 'a', 'queer', 'handkerchief', 'mockingly', 'embellished', 'with', 'all', 'the', 'gay', 'flags', 'of', 'all', 'the', 'known', 'nations', 'of', 'the', 'world', 'he', 'loved', 'to', 'dust', 'his', 'old', 'grammars', 'it', 'somehow', 'mildly', 'reminded', 'him', 'of', 'his', 'mortality', 'while', 'you', 'take', 'in', 'hand', 'to', 'school', 'others', 'and', 'to', 'teach', 'them', 'by', 'what', 'name', 'a', 'whale', 'fish', 'is', 'to', 'be', 'called', 'in', 'our', 'tongue', 'leaving', 'out', 'through', 'ignorance', 'the', 'letter', 'h', 'which', 'almost', 'alone', 'maketh', 'the', 'signification', 'of', 'the', 'word', 'you', 'deliver', 'that', 'which', 'is', 'not', 'true', 'hackluyt', 'myself', 'have', 'agreed', 'to', 'try', 'whether', 'i', 'can', 'master', 'and', 'kill', 'this', 'sperma', 'ceti', 'whale', 'for', 'i', 'could', 'never', 'hear', 'of', 'any', 'of', 'that', 'sort', 'that', 'was', 'killed', 'by', 'any', 'man', 'such', 'is', 'his', 'fierceness', 'and', 'swiftness', 'richard', 'strafford', 's', 'letter', 'from', 'the', 'bermudas', 'phil', 'trans', 'a', 'd']\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd \n",
    "import pandas as pd \n",
    "#Word Tokenization\n",
    "import nltk # import package for tokenization\n",
    "#nltk.download('punkt') # download all spporting function /files for NLTK package\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(input_file3)\n",
    "print(tokens)\n",
    "token_df=pd.DataFrame(tokens,columns=['Words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Stop words :-\n",
      "{'more', 'do', 'but', 'nor', 'all', 'from', \"mightn't\", 'during', 'been', 'too', 'further', 'our', 'am', 'being', 's', 'above', \"doesn't\", 'your', 'between', 'won', 'she', 'if', 'hers', 'shan', \"it's\", \"she's\", 'at', 'up', 'hadn', \"you've\", 're', 'same', 'i', 'didn', 'myself', 'him', 'where', 'against', 'does', \"that'll\", 'had', 'only', \"hadn't\", 'on', 'to', 'that', 'while', 'himself', 'below', 'then', 'when', 'mightn', 'doesn', 'whom', \"you'll\", 'couldn', 'because', 'what', 'these', 'has', 'd', 'not', \"shouldn't\", 'which', 'for', 'an', 'will', \"wouldn't\", 'both', 'so', 'he', 'y', 'by', 'why', 'should', \"don't\", 'you', 'off', 'theirs', 'was', 've', \"hasn't\", 'be', 'can', 'needn', 'is', 'haven', 'hasn', 'about', \"you'd\", 'did', 'once', \"should've\", 'very', 'having', 'those', 'were', 'as', 'her', 'my', 'out', 'no', 'here', 'ain', 'into', 'it', 'such', 'own', 'over', 'any', 'll', 'ma', \"aren't\", \"haven't\", \"wasn't\", 'or', 'in', 'isn', 'its', 'doing', 'the', 'yourself', 'other', \"mustn't\", \"needn't\", 'some', \"isn't\", 'itself', 'their', \"you're\", 'weren', \"couldn't\", 'they', 'mustn', 'each', 'how', 'just', 'wouldn', 'ours', 'under', 'after', 'few', 'themselves', 'again', 'ourselves', 'we', 'and', 'until', \"shan't\", 'most', 'of', 'now', 'yourselves', 'there', 't', 'shouldn', 'herself', 'yours', 'down', 'with', 'his', 'aren', 'a', 'through', \"didn't\", 'who', 'don', 'are', \"weren't\", 'have', \"won't\", 'o', 'this', 'them', 'm', 'me', 'wasn', 'than', 'before'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#To show the stop words\n",
    "#nltk.download('stopwords') #download Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(\"List of Stop words :-\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pale', 'usher', 'threadbare', 'coat', 'heart', 'body', 'brain', 'see', 'ever', 'dusting', 'old', 'lexicons', 'grammars', 'queer', 'handkerchief', 'mockingly', 'embellished', 'gay', 'flags', 'known', 'nations', 'world', 'loved', 'dust', 'old', 'grammars', 'somehow', 'mildly', 'reminded', 'mortality', 'take', 'hand', 'school', 'others', 'teach', 'name', 'whale', 'fish', 'called', 'tongue', 'leaving', 'ignorance', 'letter', 'h', 'almost', 'alone', 'maketh', 'signification', 'word', 'deliver', 'true', 'hackluyt', 'agreed', 'try', 'whether', 'master', 'kill', 'sperma', 'ceti', 'whale', 'could', 'never', 'hear', 'sort', 'killed', 'man', 'fierceness', 'swiftness', 'richard', 'strafford', 'letter', 'bermudas', 'phil', 'trans']\n"
     ]
    }
   ],
   "source": [
    "#Remove All Stop Word\n",
    "result = [i for i in tokens if not i in stop_words]# remove the word which is aviable in stopword library\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before Stremming</th>\n",
       "      <th>After Stremming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pale</td>\n",
       "      <td>pale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usher</td>\n",
       "      <td>usher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>threadbare</td>\n",
       "      <td>threadbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coat</td>\n",
       "      <td>coat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heart</td>\n",
       "      <td>heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>body</td>\n",
       "      <td>bodi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brain</td>\n",
       "      <td>brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ever</td>\n",
       "      <td>ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dusting</td>\n",
       "      <td>dust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>old</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lexicons</td>\n",
       "      <td>lexicon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>grammars</td>\n",
       "      <td>grammar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>queer</td>\n",
       "      <td>queer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>handkerchief</td>\n",
       "      <td>handkerchief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mockingly</td>\n",
       "      <td>mockingli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>embellished</td>\n",
       "      <td>embellish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gay</td>\n",
       "      <td>gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flags</td>\n",
       "      <td>flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>known</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nations</td>\n",
       "      <td>nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>loved</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dust</td>\n",
       "      <td>dust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>old</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>grammars</td>\n",
       "      <td>grammar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>somehow</td>\n",
       "      <td>somehow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mildly</td>\n",
       "      <td>mildli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>reminded</td>\n",
       "      <td>remind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mortality</td>\n",
       "      <td>mortal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>almost</td>\n",
       "      <td>almost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>alone</td>\n",
       "      <td>alon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>maketh</td>\n",
       "      <td>maketh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>signification</td>\n",
       "      <td>signif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>deliver</td>\n",
       "      <td>deliv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>hackluyt</td>\n",
       "      <td>hackluyt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>try</td>\n",
       "      <td>tri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>whether</td>\n",
       "      <td>whether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>master</td>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>kill</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>sperma</td>\n",
       "      <td>sperma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ceti</td>\n",
       "      <td>ceti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>whale</td>\n",
       "      <td>whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>could</td>\n",
       "      <td>could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>hear</td>\n",
       "      <td>hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>sort</td>\n",
       "      <td>sort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>killed</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>man</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>fierceness</td>\n",
       "      <td>fierc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>swiftness</td>\n",
       "      <td>swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>richard</td>\n",
       "      <td>richard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>strafford</td>\n",
       "      <td>strafford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>letter</td>\n",
       "      <td>letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>bermudas</td>\n",
       "      <td>bermuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>phil</td>\n",
       "      <td>phil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>trans</td>\n",
       "      <td>tran</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Before Stremming After Stremming\n",
       "0              pale            pale\n",
       "1             usher           usher\n",
       "2        threadbare       threadbar\n",
       "3              coat            coat\n",
       "4             heart           heart\n",
       "5              body            bodi\n",
       "6             brain           brain\n",
       "7               see             see\n",
       "8              ever            ever\n",
       "9           dusting            dust\n",
       "10              old             old\n",
       "11         lexicons         lexicon\n",
       "12         grammars         grammar\n",
       "13            queer           queer\n",
       "14     handkerchief    handkerchief\n",
       "15        mockingly       mockingli\n",
       "16      embellished       embellish\n",
       "17              gay             gay\n",
       "18            flags            flag\n",
       "19            known           known\n",
       "20          nations          nation\n",
       "21            world           world\n",
       "22            loved            love\n",
       "23             dust            dust\n",
       "24              old             old\n",
       "25         grammars         grammar\n",
       "26          somehow         somehow\n",
       "27           mildly          mildli\n",
       "28         reminded          remind\n",
       "29        mortality          mortal\n",
       "..              ...             ...\n",
       "44           almost          almost\n",
       "45            alone            alon\n",
       "46           maketh          maketh\n",
       "47    signification          signif\n",
       "48             word            word\n",
       "49          deliver           deliv\n",
       "50             true            true\n",
       "51         hackluyt        hackluyt\n",
       "52           agreed            agre\n",
       "53              try             tri\n",
       "54          whether         whether\n",
       "55           master          master\n",
       "56             kill            kill\n",
       "57           sperma          sperma\n",
       "58             ceti            ceti\n",
       "59            whale           whale\n",
       "60            could           could\n",
       "61            never           never\n",
       "62             hear            hear\n",
       "63             sort            sort\n",
       "64           killed            kill\n",
       "65              man             man\n",
       "66       fierceness           fierc\n",
       "67        swiftness           swift\n",
       "68          richard         richard\n",
       "69        strafford       strafford\n",
       "70           letter          letter\n",
       "71         bermudas         bermuda\n",
       "72             phil            phil\n",
       "73            trans            tran\n",
       "\n",
       "[74 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming\n",
    "import pandas as pd \n",
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "result2=[ps.stem(word)for word in result]\n",
    "pd.DataFrame(list(zip(result,result2)),columns =['Before Stremming','After Stremming'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('tagsets')\n",
    "#nltk.help.upenn_tagset()# tagset documentation\n",
    "#nltk.download('wordnet')\n",
    "from collections import defaultdict #Default Dictionary is imported from collections\n",
    "from nltk.corpus import wordnet as wn #the corpus reader wordnet is imported.\n",
    "from nltk.tag import pos_tag\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. \n",
    "#By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN) #Dictionary is created where pos_tag (first letter) are the key values \n",
    "tag_map['J'] = wn.ADJ                   #whose values are mapped with the value \n",
    "tag_map['V'] = wn.VERB                  #from wordnet dictionary. We have taken the only first letter as \n",
    "tag_map['R'] = wn.ADV\n",
    "# we will use it later in the loop.\n",
    "#tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Named entity Recognition\n",
    "from nltk.chunk import ne_chunk\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#nltk.download('words')\n",
    "tokens_NER = pos_tag(result3) # this labels each word as a part of speech\n",
    "entities = ne_chunk(tokens_NER) # this extracts entities from the list of words\n",
    "entities.draw() #pos tag in seprate window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before lemmatizer</th>\n",
       "      <th>After lemmatizer</th>\n",
       "      <th>POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pale</td>\n",
       "      <td>pale</td>\n",
       "      <td>(pale, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usher</td>\n",
       "      <td>usher</td>\n",
       "      <td>(usher, CC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>threadbare</td>\n",
       "      <td>threadbare</td>\n",
       "      <td>(threadbare, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coat</td>\n",
       "      <td>coat</td>\n",
       "      <td>(coat, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heart</td>\n",
       "      <td>heart</td>\n",
       "      <td>(heart, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>body</td>\n",
       "      <td>body</td>\n",
       "      <td>(body, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brain</td>\n",
       "      <td>brain</td>\n",
       "      <td>(brain, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>(see, VBP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ever</td>\n",
       "      <td>ever</td>\n",
       "      <td>(ever, RB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dusting</td>\n",
       "      <td>dust</td>\n",
       "      <td>(dusting, VBG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>old</td>\n",
       "      <td>old</td>\n",
       "      <td>(old, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lexicons</td>\n",
       "      <td>lexicon</td>\n",
       "      <td>(lexicons, NNS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>grammars</td>\n",
       "      <td>grammar</td>\n",
       "      <td>(grammars, NNS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>queer</td>\n",
       "      <td>queer</td>\n",
       "      <td>(queer, VBP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>handkerchief</td>\n",
       "      <td>handkerchief</td>\n",
       "      <td>(handkerchief, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mockingly</td>\n",
       "      <td>mockingly</td>\n",
       "      <td>(mockingly, RB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>embellished</td>\n",
       "      <td>embellish</td>\n",
       "      <td>(embellished, VBD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gay</td>\n",
       "      <td>gay</td>\n",
       "      <td>(gay, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flags</td>\n",
       "      <td>flag</td>\n",
       "      <td>(flags, NNS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>known</td>\n",
       "      <td>know</td>\n",
       "      <td>(known, VBN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nations</td>\n",
       "      <td>nation</td>\n",
       "      <td>(nations, NNS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>(world, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>loved</td>\n",
       "      <td>love</td>\n",
       "      <td>(loved, VBD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dust</td>\n",
       "      <td>dust</td>\n",
       "      <td>(dust, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>old</td>\n",
       "      <td>old</td>\n",
       "      <td>(old, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>grammars</td>\n",
       "      <td>grammar</td>\n",
       "      <td>(grammars, NNS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>somehow</td>\n",
       "      <td>somehow</td>\n",
       "      <td>(somehow, RB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mildly</td>\n",
       "      <td>mildly</td>\n",
       "      <td>(mildly, RB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>reminded</td>\n",
       "      <td>reminded</td>\n",
       "      <td>(reminded, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mortality</td>\n",
       "      <td>mortality</td>\n",
       "      <td>(mortality, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>almost</td>\n",
       "      <td>almost</td>\n",
       "      <td>(almost, RB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>alone</td>\n",
       "      <td>alone</td>\n",
       "      <td>(alone, RB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>maketh</td>\n",
       "      <td>maketh</td>\n",
       "      <td>(maketh, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>signification</td>\n",
       "      <td>signification</td>\n",
       "      <td>(signification, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>(word, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>deliver</td>\n",
       "      <td>deliver</td>\n",
       "      <td>(deliver, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>(true, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>hackluyt</td>\n",
       "      <td>hackluyt</td>\n",
       "      <td>(hackluyt, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agree</td>\n",
       "      <td>(agreed, VBD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>try</td>\n",
       "      <td>try</td>\n",
       "      <td>(try, IN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>whether</td>\n",
       "      <td>whether</td>\n",
       "      <td>(whether, IN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>master</td>\n",
       "      <td>master</td>\n",
       "      <td>(master, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>kill</td>\n",
       "      <td>kill</td>\n",
       "      <td>(kill, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>sperma</td>\n",
       "      <td>sperma</td>\n",
       "      <td>(sperma, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ceti</td>\n",
       "      <td>ceti</td>\n",
       "      <td>(ceti, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>whale</td>\n",
       "      <td>whale</td>\n",
       "      <td>(whale, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>could</td>\n",
       "      <td>could</td>\n",
       "      <td>(could, MD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>never</td>\n",
       "      <td>never</td>\n",
       "      <td>(never, RB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>hear</td>\n",
       "      <td>hear</td>\n",
       "      <td>(hear, VB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>sort</td>\n",
       "      <td>sort</td>\n",
       "      <td>(sort, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>killed</td>\n",
       "      <td>kill</td>\n",
       "      <td>(killed, VBN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>man</td>\n",
       "      <td>man</td>\n",
       "      <td>(man, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>fierceness</td>\n",
       "      <td>fierceness</td>\n",
       "      <td>(fierceness, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>swiftness</td>\n",
       "      <td>swiftness</td>\n",
       "      <td>(swiftness, JJ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>richard</td>\n",
       "      <td>richard</td>\n",
       "      <td>(richard, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>strafford</td>\n",
       "      <td>strafford</td>\n",
       "      <td>(strafford, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>letter</td>\n",
       "      <td>letter</td>\n",
       "      <td>(letter, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>bermudas</td>\n",
       "      <td>bermuda</td>\n",
       "      <td>(bermudas, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>phil</td>\n",
       "      <td>phil</td>\n",
       "      <td>(phil, NN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>trans</td>\n",
       "      <td>trans</td>\n",
       "      <td>(trans, NNS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Before lemmatizer After lemmatizer              POS Tag\n",
       "0               pale             pale           (pale, NN)\n",
       "1              usher            usher          (usher, CC)\n",
       "2         threadbare       threadbare     (threadbare, NN)\n",
       "3               coat             coat           (coat, JJ)\n",
       "4              heart            heart          (heart, NN)\n",
       "5               body             body           (body, NN)\n",
       "6              brain            brain          (brain, NN)\n",
       "7                see              see           (see, VBP)\n",
       "8               ever             ever           (ever, RB)\n",
       "9            dusting             dust       (dusting, VBG)\n",
       "10               old              old            (old, JJ)\n",
       "11          lexicons          lexicon      (lexicons, NNS)\n",
       "12          grammars          grammar      (grammars, NNS)\n",
       "13             queer            queer         (queer, VBP)\n",
       "14      handkerchief     handkerchief   (handkerchief, NN)\n",
       "15         mockingly        mockingly      (mockingly, RB)\n",
       "16       embellished        embellish   (embellished, VBD)\n",
       "17               gay              gay            (gay, JJ)\n",
       "18             flags             flag         (flags, NNS)\n",
       "19             known             know         (known, VBN)\n",
       "20           nations           nation       (nations, NNS)\n",
       "21             world            world          (world, NN)\n",
       "22             loved             love         (loved, VBD)\n",
       "23              dust             dust           (dust, JJ)\n",
       "24               old              old            (old, JJ)\n",
       "25          grammars          grammar      (grammars, NNS)\n",
       "26           somehow          somehow        (somehow, RB)\n",
       "27            mildly           mildly         (mildly, RB)\n",
       "28          reminded         reminded       (reminded, JJ)\n",
       "29         mortality        mortality      (mortality, NN)\n",
       "..               ...              ...                  ...\n",
       "44            almost           almost         (almost, RB)\n",
       "45             alone            alone          (alone, RB)\n",
       "46            maketh           maketh         (maketh, JJ)\n",
       "47     signification    signification  (signification, NN)\n",
       "48              word             word           (word, NN)\n",
       "49           deliver          deliver        (deliver, NN)\n",
       "50              true             true           (true, JJ)\n",
       "51          hackluyt         hackluyt       (hackluyt, NN)\n",
       "52            agreed            agree        (agreed, VBD)\n",
       "53               try              try            (try, IN)\n",
       "54           whether          whether        (whether, IN)\n",
       "55            master           master         (master, NN)\n",
       "56              kill             kill           (kill, NN)\n",
       "57            sperma           sperma         (sperma, JJ)\n",
       "58              ceti             ceti           (ceti, NN)\n",
       "59             whale            whale          (whale, NN)\n",
       "60             could            could          (could, MD)\n",
       "61             never            never          (never, RB)\n",
       "62              hear             hear           (hear, VB)\n",
       "63              sort             sort           (sort, NN)\n",
       "64            killed             kill        (killed, VBN)\n",
       "65               man              man            (man, NN)\n",
       "66        fierceness       fierceness     (fierceness, NN)\n",
       "67         swiftness        swiftness      (swiftness, JJ)\n",
       "68           richard          richard        (richard, NN)\n",
       "69         strafford        strafford      (strafford, NN)\n",
       "70            letter           letter         (letter, NN)\n",
       "71          bermudas          bermuda       (bermudas, NN)\n",
       "72              phil             phil           (phil, NN)\n",
       "73             trans            trans         (trans, NNS)\n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3=[lemmatizer.lemmatize(word,tag_map[tag[0]])for word ,tag in pos_tag(result)]\n",
    "data_lamm=pd.DataFrame(list(zip(result,result3,pos_tag(result))),columns =['Before lemmatizer','After lemmatizer',\"POS Tag\"])\n",
    "data_lamm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pale': 1,\n",
       "         'usher': 1,\n",
       "         'threadbare': 1,\n",
       "         'coat': 1,\n",
       "         'heart': 1,\n",
       "         'body': 1,\n",
       "         'brain': 1,\n",
       "         'see': 1,\n",
       "         'ever': 1,\n",
       "         'dust': 2,\n",
       "         'old': 2,\n",
       "         'lexicon': 1,\n",
       "         'grammar': 2,\n",
       "         'queer': 1,\n",
       "         'handkerchief': 1,\n",
       "         'mockingly': 1,\n",
       "         'embellish': 1,\n",
       "         'gay': 1,\n",
       "         'flag': 1,\n",
       "         'know': 1,\n",
       "         'nation': 1,\n",
       "         'world': 1,\n",
       "         'love': 1,\n",
       "         'somehow': 1,\n",
       "         'mildly': 1,\n",
       "         'reminded': 1,\n",
       "         'mortality': 1,\n",
       "         'take': 1,\n",
       "         'hand': 1,\n",
       "         'school': 1,\n",
       "         'others': 1,\n",
       "         'teach': 1,\n",
       "         'name': 1,\n",
       "         'whale': 2,\n",
       "         'fish': 1,\n",
       "         'call': 1,\n",
       "         'tongue': 1,\n",
       "         'leave': 1,\n",
       "         'ignorance': 1,\n",
       "         'letter': 2,\n",
       "         'h': 1,\n",
       "         'almost': 1,\n",
       "         'alone': 1,\n",
       "         'maketh': 1,\n",
       "         'signification': 1,\n",
       "         'word': 1,\n",
       "         'deliver': 1,\n",
       "         'true': 1,\n",
       "         'hackluyt': 1,\n",
       "         'agree': 1,\n",
       "         'try': 1,\n",
       "         'whether': 1,\n",
       "         'master': 1,\n",
       "         'kill': 2,\n",
       "         'sperma': 1,\n",
       "         'ceti': 1,\n",
       "         'could': 1,\n",
       "         'never': 1,\n",
       "         'hear': 1,\n",
       "         'sort': 1,\n",
       "         'man': 1,\n",
       "         'fierceness': 1,\n",
       "         'swiftness': 1,\n",
       "         'richard': 1,\n",
       "         'strafford': 1,\n",
       "         'bermuda': 1,\n",
       "         'phil': 1,\n",
       "         'trans': 1})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(result3)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = [] \n",
    "  \n",
    "# for i in range(0, 5): \n",
    "#     text = re.sub('[^a-zA-Z]', '', dataset['Text'][i]) \n",
    "#     text = text.lower() \n",
    "#     text = text.split() \n",
    "#     ps = PorterStemmer() \n",
    "#     text = ''.join(text) \n",
    "#     corpus.append(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
